{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_effort(incentive):\n",
    "    return 10*(1-np.exp(-incentive/400.0))\n",
    "    \n",
    "def get_improvement_in_renewal_probability(incentive):\n",
    "    effort = get_effort(incentive)\n",
    "    return 20*(1-np.exp(-effort/5.0))\n",
    "\n",
    "def gradient_improvement_in_renewal_probability(incentive):\n",
    "    dpde = 4 * np.exp(-get_effort(incentive)/5.0)\n",
    "    dedi = np.exp(-incentive/400.0)/40.0\n",
    "    dpdi = dpde * dedi\n",
    "    return  dpdi\n",
    "    \n",
    "def revenue_score(incentive, benchmark, premium):\n",
    "    cdp = get_improvement_in_renewal_probability(incentive)\n",
    "    profits = ((benchmark + (cdp*benchmark/100.0)) * premium)-incentive\n",
    "    return np.sum(profits)\n",
    "\n",
    "def score_gradient(incentive, benchmark, premium):\n",
    "    z=  np.exp(-incentive/400.0)-(incentive/400.0)-2\n",
    "    return ((benchmark * premium * np.exp(z)/400.0)-1)\n",
    "\n",
    "def second_score_gradient(incentive, benchmark, premium):\n",
    "    a = np.exp(-incentive/400.0)-(incentive/400.0)\n",
    "    b = (benchmark* premium* np.exp(a))/400.0\n",
    "    return (-(b)-(1.0/400.0))/400.0\n",
    "\n",
    "def learn(benchmark, premium, early_stopping = 5, start_incentive = 1700, min_improvement = 0.005, verbose = True):\n",
    "    incentive = start_incentive\n",
    "    best_incentive = start_incentive\n",
    "    \n",
    "    score = 0\n",
    "    best_score = 0\n",
    "    \n",
    "    counter = 0\n",
    "    best_counter = 0\n",
    "    no_improvement_counter = 0\n",
    "    \n",
    "    while True:\n",
    "        lr = (incentive - 0)\n",
    "        gradient = score_gradient(incentive, benchmark, premium)\n",
    "        try:\n",
    "            incentive += lr*(gradient*0.5 + 0.5*prev_gradient)\n",
    "        except:\n",
    "            incentive += lr*gradient\n",
    "            \n",
    "        \n",
    "        score = revenue_score(incentive, benchmark, premium)\n",
    "        counter +=1\n",
    "        prev_gradient = gradient\n",
    "\n",
    "        if (score-best_score> min_improvement):\n",
    "            best_score = score\n",
    "            best_incentive = incentive\n",
    "            best_counter = counter\n",
    "            \n",
    "            no_improvement_counter = 0\n",
    "            if verbose: print \"Epoch: {}, Incentive: {}, Score: {}, Gradient: {}\".format(counter,incentive, score, gradient)\n",
    "        else:\n",
    "            if (no_improvement_counter > early_stopping):\n",
    "                if verbose: print \"Early Stopping, Best Iteration Round: {}\".format(best_counter)\n",
    "                return best_incentive, best_score\n",
    "            else:\n",
    "                no_improvement_counter +=1\n",
    "                if verbose: print \"Epoch: {}, Incentive: {}, Score: {}, Gradient: {}\".format(counter,incentive, score, gradient)\n",
    "\n",
    "                    \n",
    "def annealing(benchmark, premium, num_annealing = 10):\n",
    "    results = []\n",
    "    for incentive in range(0,premium,int(float(premium)/num_annealing)):\n",
    "        results.append(learn(benchmark, premium, early_stopping = 5, start_incentive = incentive, min_improvement = 0.005, verbose = False))\n",
    "    return sorted(results, key = lambda x: x[1])[-1][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_files = [pd.read_csv(\"best_ensemble/csv/eda{}.csv\".format(i)) for i in range(1,11)]\n",
    "submit_files += [pd.read_csv(\"best_ensemble_tid/csv/eda{}.csv\".format(i)) for i in range(1,11)]\n",
    "submit_files += [pd.read_csv(\"best_ensemble_bagged/csv/eda{}.csv\".format(i)) for i in range(1,11)]\n",
    "submit_files += [pd.read_csv(\"best_ensemble_tid_bagged/csv/eda{}.csv\".format(i)) for i in range(1,11)]\n",
    "\n",
    "renewals = [df[\"renewal\"].values for df in submit_files]\n",
    "incentives = [df[\"incentives\"].values for df in submit_files]\n",
    "ids = submit_files[0][\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 0 Predictions\n",
      "Done 1 Predictions\n",
      "Done 2 Predictions\n",
      "Done 3 Predictions\n",
      "Done 4 Predictions\n",
      "Done 5 Predictions\n",
      "Done 6 Predictions\n",
      "Done 7 Predictions\n",
      "Done 8 Predictions\n",
      "Done 9 Predictions\n",
      "Done 10 Predictions\n",
      "Done 11 Predictions\n",
      "Done 12 Predictions\n",
      "Done 13 Predictions\n",
      "Done 14 Predictions\n",
      "Done 15 Predictions\n",
      "Done 16 Predictions\n",
      "Done 17 Predictions\n",
      "Done 18 Predictions\n",
      "Done 19 Predictions\n",
      "Done 20 Predictions\n",
      "Done 21 Predictions\n",
      "Done 22 Predictions\n",
      "Done 23 Predictions\n",
      "Done 24 Predictions\n",
      "Done 25 Predictions\n",
      "Done 26 Predictions\n",
      "Done 27 Predictions\n",
      "Done 28 Predictions\n",
      "Done 29 Predictions\n",
      "Done 30 Predictions\n",
      "Done 31 Predictions\n",
      "Done 32 Predictions\n",
      "Done 33 Predictions\n",
      "Done 34 Predictions\n",
      "Done 35 Predictions\n",
      "Done 36 Predictions\n",
      "Done 37 Predictions\n",
      "Done 38 Predictions\n",
      "Done 39 Predictions\n"
     ]
    }
   ],
   "source": [
    "premiums = pd.read_csv(\"data/sample_submission_sLex1ul.csv\", usecols = [\"id\"]).merge(pd.read_csv(\"data/test_66516Ee.csv\", usecols = [\"id\",\"premium\"]), how = \"left\", on=\"id\")[\"premium\"]\n",
    "all_predicted_incentives = []\n",
    "\n",
    "for c, benchmarks in enumerate(renewals):\n",
    "    print \"Done {} Predictions\".format(c)\n",
    "    \n",
    "    incentive_predictions = []\n",
    "    for b, p in zip(benchmarks, premiums):\n",
    "        incentive_predictions.append(annealing(b, p))\n",
    "    all_predicted_incentives.append(np.array(incentive_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predicted_incentives = pd.DataFrame(np.array(all_predicted_incentives).T).mean(axis=1)\n",
    "incentives = pd.DataFrame(np.array(incentives).T).mean(axis=1)\n",
    "\n",
    "incentives = (incentives+all_predicted_incentives)/2\n",
    "renewals = pd.DataFrame(np.array(renewals).T).rank(pct = True, axis=0).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission[\"renewal\"] = renewals\n",
    "submission[\"incentives\"] = incentives\n",
    "submission[\"id\"] = ids\n",
    "submission.to_csv(\"submission/incentives_recalculated_ensemble.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
